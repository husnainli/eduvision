import streamlit as st
import fitz  # PyMuPDF
import re

from utils.embeddings import chunk_text, embed_chunks, retrieve_similar_chunks
from utils.llm import query_llama3
from utils.translate import translate_text
from utils.jais_llm import query_jais

# -------------------------------
# ğŸ§¼ Arabic Text Cleaning Utility
# -------------------------------
def clean_arabic_text(text):
    """Cleans and normalizes Arabic text."""
    diacritics = re.compile(r"[Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù“]")
    text = re.sub(diacritics, '', text)
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub(r"Ù‰", "ÙŠ", text)
    text = re.sub(r"Ø¤", "Ùˆ", text)
    text = re.sub(r"Ø¦", "ÙŠ", text)
    text = re.sub(r"Ø©", "Ù‡", text)
    text = re.sub(r"[^\u0600-\u06FF\s]", '', text)
    return re.sub(r"\s+", ' ', text).strip()

# -------------------------------
# ğŸ“„ PDF Text Extraction
# -------------------------------
def extract_text_from_pdf(pdf_file):
    """Extracts and cleans Arabic text from uploaded PDF."""
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    raw_text = ''.join(page.get_text() for page in doc)
    return clean_arabic_text(raw_text)

def sanitize_for_translation(text):
    return text.replace('\n', ' ').strip()

@st.cache_resource(show_spinner=False)
def get_vectorstore(chunks):
    return embed_chunks(chunks)

# -------------------------------
# ğŸš€ Streamlit App Initialization
# -------------------------------
st.set_page_config(page_title="ğŸ“š EduVision AI", layout="wide")
st.title("ğŸ¤– EduVision AI")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# -------------------------------
# ğŸ“¤ PDF Upload
# -------------------------------
uploaded_file = st.file_uploader("ğŸ“¤ Upload an Arabic PDF", type=["pdf"])

if uploaded_file:
    st.success("âœ… PDF uploaded successfully!")

    # # âœ… Test translation call (for debug)
    # with st.spinner("ğŸŒ Testing translation function..."):
    #     test_text = "Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ù‡Ùˆ Ø³Ø±Ø¯ ØªØ§Ø±ÙŠØ®ÙŠ Ø¹Ù† Ø§Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŒ ÙˆØ§Ù„Ø°ÙƒØ±Ù‰ Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯ Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„ÙÙŠØµÙ„ØŒ ÙˆØ§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ø¹ÙˆØ¯ Ø§Ù„Ù…Ù„Ù‚Ø¨ Ø¨Ø§Ù„Ù…ØºÙÙˆØ± Ù„Ù‡."
    #     translation_result = translate_text(test_text)
    #     st.markdown("ğŸ” **Test Translation Result:**")
    #     st.markdown(f"ğŸ“˜ Original Arabic: `{test_text}`")
    #     st.markdown(f"ğŸ“— English Translation: `{translation_result}`")

    # ğŸ” Extract and clean text
    with st.spinner("ğŸ§¼ Extracting and cleaning text..."):
        pdf_text = extract_text_from_pdf(uploaded_file)

    # with st.expander("ğŸ“– Preview Cleaned Text"):
    #     st.text_area("First 2000 characters of cleaned text:", value=pdf_text[:2000], height=300)

    # ğŸ”„ Split into chunks
    with st.spinner("ğŸ”„ Splitting text into chunks..."):
        chunks = chunk_text(pdf_text)
        # st.write(f"ğŸ”¹ Total Chunks Created: {len(chunks)}")

    # ğŸ§  Generate and store embeddings
    with st.spinner("ğŸ§  Embedding text and storing in vector DB..."):
        vectorstore = get_vectorstore(chunks)
        # st.success("âœ… Embeddings successfully stored!")

    # # ğŸ” Simulated retrieval preview
    # with st.expander("ğŸ§  Example Retrieval"):
    #     sample_query = "Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©ØŸ"
    #     st.write(f"ğŸ” Example Query: `{sample_query}`")
    #     docs = vectorstore.similarity_search(sample_query, k=4)
    #     for i, doc in enumerate(docs, 1):
    #         st.markdown(f"**Document {i}:**\n{doc.page_content[:500]}")

    # ---------------------------------
    # ğŸ’¬ Interactive Q&A Chat Interface
    # ---------------------------------
    st.divider()
    st.subheader("ğŸ’¬ Ask a question based on the uploaded PDF")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("âœï¸ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ (Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)...")

    if user_input:
        # Show user question
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # Retrieve relevant document chunks
        with st.spinner("ğŸ¤– Generating response using LLaMA 3..."):
            retrieved_docs = retrieve_similar_chunks(vectorstore, user_input, k=6)
            context = "\n\n".join(doc.page_content for doc in retrieved_docs)
            # context = "\n\n".join(clean_arabic_text(doc.page_content) for doc in retrieved_docs)

            print(context)

            prompt = (
                f"Ø§Ù„Ø³Ø¤Ø§Ù„:\n{user_input}\n\n"
                f"Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©:\n{context}\n\n"
                "Ø£Ø¬Ø¨ Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø© ÙˆØ´Ø§Ù…Ù„Ø© Ù…Ø³ØªÙ†Ø¯Ù‹Ø§ ÙÙ‚Ø· Ø¥Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø£Ø¹Ù„Ø§Ù‡."
                "ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø· Ø¯ÙˆÙ† Ø£ÙŠ ÙƒÙ„Ù…Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø£Ùˆ Ù„ØºØ§Øª Ø£Ø®Ø±Ù‰."
                "Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø· Ø¯ÙˆÙ† ØªØ£Ù„ÙŠÙ."
            )

            response = query_llama3(prompt)
            # response = query_jais(prompt)

        response_key = f"translated_response_{len(st.session_state.messages)}"

        with st.chat_message("assistant"):
            st.markdown(response)

        # âœ… Test translation call (for debug)
        with st.spinner("Translating to English..."):
            translation_result = translate_text(response)
            st.markdown(f"ğŸ“— English Translation: `{translation_result}`")

        st.session_state.messages.append({"role": "assistant", "content": response})

else:
    st.info("â¬†ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù PDF Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.")
